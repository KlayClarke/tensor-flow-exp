{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1SC5OAJexG6OXaAh5PEhU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KlayClarke/tf--experimentation/blob/main/learning/tf/linear_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67aujHRWbstp",
        "outputId": "8dccf256-6f0b-4eee-98e5-02059adf4a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 3.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 462 kB 5.4 MB/s \n",
            "\u001b[?25h2.8.0\n"
          ]
        }
      ],
      "source": [
        "# install and import tensorflow\n",
        "!pip install -q tensorflow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRov2Ldbb02j",
        "outputId": "5a8048b3-b808-428a-b03f-0a8c60358f67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
              " 'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "         1.189e-01],\n",
              "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "         8.902e-02],\n",
              "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "         8.758e-02],\n",
              "        ...,\n",
              "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "         7.820e-02],\n",
              "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "         1.240e-01],\n",
              "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "         7.039e-02]]),\n",
              " 'data_module': 'sklearn.datasets.data',\n",
              " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "        'smoothness error', 'compactness error', 'concavity error',\n",
              "        'concave points error', 'symmetry error',\n",
              "        'fractal dimension error', 'worst radius', 'worst texture',\n",
              "        'worst perimeter', 'worst area', 'worst smoothness',\n",
              "        'worst compactness', 'worst concavity', 'worst concave points',\n",
              "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
              " 'filename': 'breast_cancer.csv',\n",
              " 'frame': None,\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
              " 'target_names': array(['malignant', 'benign'], dtype='<U9')}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check type of data (bunch acts a dict where you can treat keys like attributes)\n",
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3KFYdbWcfhv",
        "outputId": "5827c6f0-ec17-4852-fc85-d32f8f4e4e5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkGhCkFSclU3",
        "outputId": "4321f3f4-edab-4b24-992c-f74484f53760"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check shape of x\n",
        "data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PBYZDNzd3oP",
        "outputId": "3acb72ac-656b-4a4d-c580-3a3fc23bdb6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqrTq_m1d9_k",
        "outputId": "fc41b797-b212-4162-e1f9-e87f2478a013"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wE3CnNseMx2",
        "outputId": "11aa8dd9-0cd4-4149-d7f1-cd9b1c55a2ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my6ONf93ee2F",
        "outputId": "552f50fe-88ba-455e-960a-e3d88c997627"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.feature_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HF2aMOnelxr",
        "outputId": "40cfd3bf-17c7-480c-e002-d8bfd0ebbf56"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "zdvjWJD7esp9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into train and test sets\n",
        "# this lets us simulate future data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=.33)\n",
        "N, D = X_train.shape"
      ],
      "metadata": {
        "id": "rKIbWkjte4Fe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scale the data (standardization)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# import not to expose any test data to training pipeline\n",
        "X_test = scaler.transform(X_test) "
      ],
      "metadata": {
        "id": "y0tC0fjwg5Dx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the tensorflow model\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Input(shape=(D,)),\n",
        "                                    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# or\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "0ScDxmVAhOgb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "9iWyJwLsi9Te"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WijBY519kS-W",
        "outputId": "f5343b56-d4d2-44f4-e121-d8f699aeb8f4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 21ms/step - loss: 0.9077 - accuracy: 0.3806 - val_loss: 0.9464 - val_accuracy: 0.3883\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8197 - accuracy: 0.4331 - val_loss: 0.8441 - val_accuracy: 0.5106\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7396 - accuracy: 0.5092 - val_loss: 0.7545 - val_accuracy: 0.6330\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6700 - accuracy: 0.5879 - val_loss: 0.6770 - val_accuracy: 0.7234\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.6113 - accuracy: 0.6640 - val_loss: 0.6095 - val_accuracy: 0.7766\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5593 - accuracy: 0.7349 - val_loss: 0.5536 - val_accuracy: 0.7766\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.7559 - val_loss: 0.5051 - val_accuracy: 0.8032\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4797 - accuracy: 0.7822 - val_loss: 0.4650 - val_accuracy: 0.8298\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4490 - accuracy: 0.8215 - val_loss: 0.4303 - val_accuracy: 0.8457\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8425 - val_loss: 0.4012 - val_accuracy: 0.8617\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8583 - val_loss: 0.3761 - val_accuracy: 0.8883\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3782 - accuracy: 0.8793 - val_loss: 0.3538 - val_accuracy: 0.8989\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3598 - accuracy: 0.8898 - val_loss: 0.3344 - val_accuracy: 0.9149\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3435 - accuracy: 0.8976 - val_loss: 0.3174 - val_accuracy: 0.9202\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.9108 - val_loss: 0.3023 - val_accuracy: 0.9255\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3158 - accuracy: 0.9160 - val_loss: 0.2887 - val_accuracy: 0.9255\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3041 - accuracy: 0.9160 - val_loss: 0.2761 - val_accuracy: 0.9309\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2928 - accuracy: 0.9265 - val_loss: 0.2653 - val_accuracy: 0.9362\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2828 - accuracy: 0.9265 - val_loss: 0.2554 - val_accuracy: 0.9415\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2737 - accuracy: 0.9318 - val_loss: 0.2465 - val_accuracy: 0.9415\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2652 - accuracy: 0.9370 - val_loss: 0.2381 - val_accuracy: 0.9468\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2572 - accuracy: 0.9449 - val_loss: 0.2306 - val_accuracy: 0.9468\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2497 - accuracy: 0.9475 - val_loss: 0.2239 - val_accuracy: 0.9468\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2429 - accuracy: 0.9501 - val_loss: 0.2176 - val_accuracy: 0.9468\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2365 - accuracy: 0.9528 - val_loss: 0.2116 - val_accuracy: 0.9468\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2304 - accuracy: 0.9528 - val_loss: 0.2062 - val_accuracy: 0.9468\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2247 - accuracy: 0.9554 - val_loss: 0.2012 - val_accuracy: 0.9468\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2193 - accuracy: 0.9554 - val_loss: 0.1965 - val_accuracy: 0.9468\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2144 - accuracy: 0.9554 - val_loss: 0.1921 - val_accuracy: 0.9521\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2096 - accuracy: 0.9554 - val_loss: 0.1879 - val_accuracy: 0.9521\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2052 - accuracy: 0.9580 - val_loss: 0.1840 - val_accuracy: 0.9574\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2008 - accuracy: 0.9606 - val_loss: 0.1803 - val_accuracy: 0.9574\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1968 - accuracy: 0.9606 - val_loss: 0.1768 - val_accuracy: 0.9574\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1931 - accuracy: 0.9606 - val_loss: 0.1735 - val_accuracy: 0.9574\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1893 - accuracy: 0.9606 - val_loss: 0.1704 - val_accuracy: 0.9574\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1858 - accuracy: 0.9606 - val_loss: 0.1675 - val_accuracy: 0.9574\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1826 - accuracy: 0.9606 - val_loss: 0.1647 - val_accuracy: 0.9574\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1793 - accuracy: 0.9633 - val_loss: 0.1620 - val_accuracy: 0.9574\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1763 - accuracy: 0.9659 - val_loss: 0.1596 - val_accuracy: 0.9574\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1734 - accuracy: 0.9659 - val_loss: 0.1572 - val_accuracy: 0.9574\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.9685 - val_loss: 0.1549 - val_accuracy: 0.9574\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1681 - accuracy: 0.9685 - val_loss: 0.1526 - val_accuracy: 0.9574\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1654 - accuracy: 0.9685 - val_loss: 0.1505 - val_accuracy: 0.9574\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.9711 - val_loss: 0.1485 - val_accuracy: 0.9628\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1607 - accuracy: 0.9711 - val_loss: 0.1466 - val_accuracy: 0.9628\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1584 - accuracy: 0.9711 - val_loss: 0.1448 - val_accuracy: 0.9628\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1563 - accuracy: 0.9711 - val_loss: 0.1430 - val_accuracy: 0.9628\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1541 - accuracy: 0.9711 - val_loss: 0.1414 - val_accuracy: 0.9628\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1522 - accuracy: 0.9711 - val_loss: 0.1397 - val_accuracy: 0.9628\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1502 - accuracy: 0.9711 - val_loss: 0.1381 - val_accuracy: 0.9628\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1483 - accuracy: 0.9711 - val_loss: 0.1366 - val_accuracy: 0.9628\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1465 - accuracy: 0.9711 - val_loss: 0.1353 - val_accuracy: 0.9628\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.1447 - accuracy: 0.9711 - val_loss: 0.1339 - val_accuracy: 0.9628\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1432 - accuracy: 0.9711 - val_loss: 0.1325 - val_accuracy: 0.9628\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1414 - accuracy: 0.9711 - val_loss: 0.1312 - val_accuracy: 0.9628\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1398 - accuracy: 0.9711 - val_loss: 0.1300 - val_accuracy: 0.9628\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1383 - accuracy: 0.9711 - val_loss: 0.1288 - val_accuracy: 0.9628\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1369 - accuracy: 0.9711 - val_loss: 0.1276 - val_accuracy: 0.9628\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1354 - accuracy: 0.9711 - val_loss: 0.1265 - val_accuracy: 0.9628\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1340 - accuracy: 0.9711 - val_loss: 0.1254 - val_accuracy: 0.9628\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1327 - accuracy: 0.9711 - val_loss: 0.1244 - val_accuracy: 0.9628\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1314 - accuracy: 0.9711 - val_loss: 0.1233 - val_accuracy: 0.9628\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.1301 - accuracy: 0.9711 - val_loss: 0.1224 - val_accuracy: 0.9628\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1289 - accuracy: 0.9711 - val_loss: 0.1214 - val_accuracy: 0.9628\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1277 - accuracy: 0.9711 - val_loss: 0.1205 - val_accuracy: 0.9628\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1265 - accuracy: 0.9738 - val_loss: 0.1196 - val_accuracy: 0.9628\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1254 - accuracy: 0.9738 - val_loss: 0.1187 - val_accuracy: 0.9628\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1242 - accuracy: 0.9738 - val_loss: 0.1179 - val_accuracy: 0.9628\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1232 - accuracy: 0.9738 - val_loss: 0.1171 - val_accuracy: 0.9628\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9738 - val_loss: 0.1163 - val_accuracy: 0.9628\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1211 - accuracy: 0.9738 - val_loss: 0.1156 - val_accuracy: 0.9628\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1202 - accuracy: 0.9738 - val_loss: 0.1148 - val_accuracy: 0.9628\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1192 - accuracy: 0.9738 - val_loss: 0.1141 - val_accuracy: 0.9628\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1182 - accuracy: 0.9738 - val_loss: 0.1134 - val_accuracy: 0.9628\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1173 - accuracy: 0.9738 - val_loss: 0.1126 - val_accuracy: 0.9628\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1164 - accuracy: 0.9738 - val_loss: 0.1120 - val_accuracy: 0.9628\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.1155 - accuracy: 0.9738 - val_loss: 0.1113 - val_accuracy: 0.9628\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1147 - accuracy: 0.9764 - val_loss: 0.1107 - val_accuracy: 0.9628\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1139 - accuracy: 0.9764 - val_loss: 0.1101 - val_accuracy: 0.9628\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1130 - accuracy: 0.9764 - val_loss: 0.1095 - val_accuracy: 0.9628\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1123 - accuracy: 0.9738 - val_loss: 0.1089 - val_accuracy: 0.9628\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1115 - accuracy: 0.9738 - val_loss: 0.1083 - val_accuracy: 0.9628\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1107 - accuracy: 0.9738 - val_loss: 0.1078 - val_accuracy: 0.9628\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1099 - accuracy: 0.9738 - val_loss: 0.1072 - val_accuracy: 0.9628\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1092 - accuracy: 0.9738 - val_loss: 0.1067 - val_accuracy: 0.9628\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1085 - accuracy: 0.9738 - val_loss: 0.1062 - val_accuracy: 0.9628\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1078 - accuracy: 0.9738 - val_loss: 0.1057 - val_accuracy: 0.9628\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1071 - accuracy: 0.9764 - val_loss: 0.1052 - val_accuracy: 0.9628\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.1064 - accuracy: 0.9764 - val_loss: 0.1047 - val_accuracy: 0.9628\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.1058 - accuracy: 0.9764 - val_loss: 0.1042 - val_accuracy: 0.9628\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1052 - accuracy: 0.9764 - val_loss: 0.1038 - val_accuracy: 0.9628\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1045 - accuracy: 0.9764 - val_loss: 0.1033 - val_accuracy: 0.9628\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.9764 - val_loss: 0.1029 - val_accuracy: 0.9628\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.9764 - val_loss: 0.1024 - val_accuracy: 0.9628\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1027 - accuracy: 0.9790 - val_loss: 0.1020 - val_accuracy: 0.9628\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1021 - accuracy: 0.9790 - val_loss: 0.1016 - val_accuracy: 0.9628\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1016 - accuracy: 0.9790 - val_loss: 0.1012 - val_accuracy: 0.9628\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.1010 - accuracy: 0.9790 - val_loss: 0.1008 - val_accuracy: 0.9628\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1005 - accuracy: 0.9816 - val_loss: 0.1004 - val_accuracy: 0.9628\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.1000 - accuracy: 0.9816 - val_loss: 0.1000 - val_accuracy: 0.9628\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0994 - accuracy: 0.9816 - val_loss: 0.0996 - val_accuracy: 0.9628\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0989 - accuracy: 0.9816 - val_loss: 0.0993 - val_accuracy: 0.9628\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0984 - accuracy: 0.9816 - val_loss: 0.0989 - val_accuracy: 0.9628\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0979 - accuracy: 0.9816 - val_loss: 0.0986 - val_accuracy: 0.9628\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0974 - accuracy: 0.9816 - val_loss: 0.0982 - val_accuracy: 0.9628\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0969 - accuracy: 0.9816 - val_loss: 0.0978 - val_accuracy: 0.9628\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0964 - accuracy: 0.9816 - val_loss: 0.0975 - val_accuracy: 0.9628\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0960 - accuracy: 0.9816 - val_loss: 0.0972 - val_accuracy: 0.9628\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0955 - accuracy: 0.9816 - val_loss: 0.0968 - val_accuracy: 0.9628\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0950 - accuracy: 0.9816 - val_loss: 0.0965 - val_accuracy: 0.9628\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0946 - accuracy: 0.9843 - val_loss: 0.0962 - val_accuracy: 0.9628\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0942 - accuracy: 0.9843 - val_loss: 0.0959 - val_accuracy: 0.9628\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0938 - accuracy: 0.9843 - val_loss: 0.0956 - val_accuracy: 0.9628\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0934 - accuracy: 0.9843 - val_loss: 0.0953 - val_accuracy: 0.9628\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 0.9843 - val_loss: 0.0950 - val_accuracy: 0.9628\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0925 - accuracy: 0.9843 - val_loss: 0.0948 - val_accuracy: 0.9628\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0921 - accuracy: 0.9843 - val_loss: 0.0945 - val_accuracy: 0.9628\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0917 - accuracy: 0.9843 - val_loss: 0.0942 - val_accuracy: 0.9628\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0913 - accuracy: 0.9843 - val_loss: 0.0939 - val_accuracy: 0.9628\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0909 - accuracy: 0.9843 - val_loss: 0.0937 - val_accuracy: 0.9628\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0906 - accuracy: 0.9843 - val_loss: 0.0933 - val_accuracy: 0.9681\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0902 - accuracy: 0.9843 - val_loss: 0.0931 - val_accuracy: 0.9681\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0898 - accuracy: 0.9843 - val_loss: 0.0929 - val_accuracy: 0.9681\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0895 - accuracy: 0.9843 - val_loss: 0.0926 - val_accuracy: 0.9681\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0891 - accuracy: 0.9843 - val_loss: 0.0924 - val_accuracy: 0.9681\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0888 - accuracy: 0.9843 - val_loss: 0.0921 - val_accuracy: 0.9681\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0885 - accuracy: 0.9843 - val_loss: 0.0919 - val_accuracy: 0.9681\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0881 - accuracy: 0.9843 - val_loss: 0.0917 - val_accuracy: 0.9681\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0878 - accuracy: 0.9843 - val_loss: 0.0914 - val_accuracy: 0.9681\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9843 - val_loss: 0.0912 - val_accuracy: 0.9681\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0871 - accuracy: 0.9843 - val_loss: 0.0909 - val_accuracy: 0.9681\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.9843 - val_loss: 0.0908 - val_accuracy: 0.9681\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0865 - accuracy: 0.9843 - val_loss: 0.0906 - val_accuracy: 0.9681\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0862 - accuracy: 0.9843 - val_loss: 0.0904 - val_accuracy: 0.9681\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.9843 - val_loss: 0.0901 - val_accuracy: 0.9681\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0855 - accuracy: 0.9843 - val_loss: 0.0899 - val_accuracy: 0.9681\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9843 - val_loss: 0.0897 - val_accuracy: 0.9681\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0850 - accuracy: 0.9843 - val_loss: 0.0895 - val_accuracy: 0.9681\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0847 - accuracy: 0.9843 - val_loss: 0.0894 - val_accuracy: 0.9681\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0844 - accuracy: 0.9843 - val_loss: 0.0892 - val_accuracy: 0.9681\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0841 - accuracy: 0.9843 - val_loss: 0.0889 - val_accuracy: 0.9681\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0838 - accuracy: 0.9843 - val_loss: 0.0887 - val_accuracy: 0.9681\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0835 - accuracy: 0.9843 - val_loss: 0.0885 - val_accuracy: 0.9681\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0833 - accuracy: 0.9843 - val_loss: 0.0883 - val_accuracy: 0.9681\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0830 - accuracy: 0.9843 - val_loss: 0.0881 - val_accuracy: 0.9681\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0827 - accuracy: 0.9843 - val_loss: 0.0879 - val_accuracy: 0.9681\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0825 - accuracy: 0.9843 - val_loss: 0.0878 - val_accuracy: 0.9681\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9843 - val_loss: 0.0876 - val_accuracy: 0.9681\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.9843 - val_loss: 0.0875 - val_accuracy: 0.9681\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0817 - accuracy: 0.9843 - val_loss: 0.0873 - val_accuracy: 0.9681\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0814 - accuracy: 0.9843 - val_loss: 0.0871 - val_accuracy: 0.9681\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0812 - accuracy: 0.9843 - val_loss: 0.0870 - val_accuracy: 0.9681\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0809 - accuracy: 0.9843 - val_loss: 0.0867 - val_accuracy: 0.9734\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0807 - accuracy: 0.9843 - val_loss: 0.0866 - val_accuracy: 0.9734\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0805 - accuracy: 0.9843 - val_loss: 0.0864 - val_accuracy: 0.9734\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0802 - accuracy: 0.9843 - val_loss: 0.0862 - val_accuracy: 0.9734\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0800 - accuracy: 0.9843 - val_loss: 0.0860 - val_accuracy: 0.9734\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0798 - accuracy: 0.9843 - val_loss: 0.0859 - val_accuracy: 0.9734\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0795 - accuracy: 0.9843 - val_loss: 0.0857 - val_accuracy: 0.9734\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0793 - accuracy: 0.9843 - val_loss: 0.0855 - val_accuracy: 0.9734\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0791 - accuracy: 0.9843 - val_loss: 0.0854 - val_accuracy: 0.9734\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9843 - val_loss: 0.0853 - val_accuracy: 0.9734\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0786 - accuracy: 0.9843 - val_loss: 0.0852 - val_accuracy: 0.9734\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0784 - accuracy: 0.9843 - val_loss: 0.0850 - val_accuracy: 0.9734\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0782 - accuracy: 0.9843 - val_loss: 0.0849 - val_accuracy: 0.9734\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.0780 - accuracy: 0.9843 - val_loss: 0.0847 - val_accuracy: 0.9734\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0778 - accuracy: 0.9843 - val_loss: 0.0847 - val_accuracy: 0.9734\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0776 - accuracy: 0.9843 - val_loss: 0.0845 - val_accuracy: 0.9734\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0774 - accuracy: 0.9869 - val_loss: 0.0844 - val_accuracy: 0.9734\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9869 - val_loss: 0.0842 - val_accuracy: 0.9734\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0770 - accuracy: 0.9869 - val_loss: 0.0841 - val_accuracy: 0.9734\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0768 - accuracy: 0.9869 - val_loss: 0.0839 - val_accuracy: 0.9734\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0766 - accuracy: 0.9869 - val_loss: 0.0837 - val_accuracy: 0.9734\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0764 - accuracy: 0.9869 - val_loss: 0.0836 - val_accuracy: 0.9734\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0762 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9734\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0761 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9734\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0758 - accuracy: 0.9869 - val_loss: 0.0833 - val_accuracy: 0.9734\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0756 - accuracy: 0.9869 - val_loss: 0.0831 - val_accuracy: 0.9734\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0755 - accuracy: 0.9869 - val_loss: 0.0830 - val_accuracy: 0.9734\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0753 - accuracy: 0.9869 - val_loss: 0.0829 - val_accuracy: 0.9734\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0751 - accuracy: 0.9869 - val_loss: 0.0827 - val_accuracy: 0.9734\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0749 - accuracy: 0.9869 - val_loss: 0.0826 - val_accuracy: 0.9734\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0747 - accuracy: 0.9869 - val_loss: 0.0825 - val_accuracy: 0.9734\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0745 - accuracy: 0.9869 - val_loss: 0.0824 - val_accuracy: 0.9734\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0744 - accuracy: 0.9869 - val_loss: 0.0822 - val_accuracy: 0.9734\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.0742 - accuracy: 0.9869 - val_loss: 0.0822 - val_accuracy: 0.9734\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0740 - accuracy: 0.9869 - val_loss: 0.0820 - val_accuracy: 0.9734\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0739 - accuracy: 0.9869 - val_loss: 0.0819 - val_accuracy: 0.9734\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0737 - accuracy: 0.9869 - val_loss: 0.0818 - val_accuracy: 0.9734\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0735 - accuracy: 0.9869 - val_loss: 0.0816 - val_accuracy: 0.9734\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0734 - accuracy: 0.9869 - val_loss: 0.0816 - val_accuracy: 0.9734\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0732 - accuracy: 0.9869 - val_loss: 0.0814 - val_accuracy: 0.9734\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 0.9869 - val_loss: 0.0813 - val_accuracy: 0.9734\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0729 - accuracy: 0.9869 - val_loss: 0.0813 - val_accuracy: 0.9734\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0727 - accuracy: 0.9869 - val_loss: 0.0812 - val_accuracy: 0.9734\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0726 - accuracy: 0.9869 - val_loss: 0.0810 - val_accuracy: 0.9734\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0724 - accuracy: 0.9869 - val_loss: 0.0809 - val_accuracy: 0.9734\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 0.9869 - val_loss: 0.0808 - val_accuracy: 0.9734\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0721 - accuracy: 0.9869 - val_loss: 0.0806 - val_accuracy: 0.9734\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9869 - val_loss: 0.0805 - val_accuracy: 0.9734\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0718 - accuracy: 0.9869 - val_loss: 0.0804 - val_accuracy: 0.9734\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9869 - val_loss: 0.0803 - val_accuracy: 0.9734\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9869 - val_loss: 0.0802 - val_accuracy: 0.9734\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.9869 - val_loss: 0.0801 - val_accuracy: 0.9734\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9869 - val_loss: 0.0801 - val_accuracy: 0.9734\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9869 - val_loss: 0.0800 - val_accuracy: 0.9734\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9869 - val_loss: 0.0798 - val_accuracy: 0.9734\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9869 - val_loss: 0.0797 - val_accuracy: 0.9734\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9869 - val_loss: 0.0796 - val_accuracy: 0.9734\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9869 - val_loss: 0.0795 - val_accuracy: 0.9734\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9869 - val_loss: 0.0795 - val_accuracy: 0.9734\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9869 - val_loss: 0.0794 - val_accuracy: 0.9734\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9869 - val_loss: 0.0793 - val_accuracy: 0.9734\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0700 - accuracy: 0.9869 - val_loss: 0.0791 - val_accuracy: 0.9734\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9869 - val_loss: 0.0791 - val_accuracy: 0.9734\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9869 - val_loss: 0.0789 - val_accuracy: 0.9734\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9869 - val_loss: 0.0789 - val_accuracy: 0.9734\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0694 - accuracy: 0.9869 - val_loss: 0.0788 - val_accuracy: 0.9734\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9869 - val_loss: 0.0787 - val_accuracy: 0.9734\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0692 - accuracy: 0.9869 - val_loss: 0.0787 - val_accuracy: 0.9734\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9869 - val_loss: 0.0786 - val_accuracy: 0.9734\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9869 - val_loss: 0.0784 - val_accuracy: 0.9734\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9869 - val_loss: 0.0783 - val_accuracy: 0.9734\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9869 - val_loss: 0.0783 - val_accuracy: 0.9734\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0685 - accuracy: 0.9869 - val_loss: 0.0782 - val_accuracy: 0.9734\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0684 - accuracy: 0.9869 - val_loss: 0.0781 - val_accuracy: 0.9734\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9869 - val_loss: 0.0781 - val_accuracy: 0.9734\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9869 - val_loss: 0.0779 - val_accuracy: 0.9734\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9869 - val_loss: 0.0778 - val_accuracy: 0.9734\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0679 - accuracy: 0.9869 - val_loss: 0.0776 - val_accuracy: 0.9734\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9869 - val_loss: 0.0775 - val_accuracy: 0.9734\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9869 - val_loss: 0.0775 - val_accuracy: 0.9734\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9869 - val_loss: 0.0773 - val_accuracy: 0.9734\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9869 - val_loss: 0.0773 - val_accuracy: 0.9734\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9869 - val_loss: 0.0773 - val_accuracy: 0.9734\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0672 - accuracy: 0.9869 - val_loss: 0.0772 - val_accuracy: 0.9734\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9869 - val_loss: 0.0771 - val_accuracy: 0.9734\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0670 - accuracy: 0.9869 - val_loss: 0.0769 - val_accuracy: 0.9734\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.9869 - val_loss: 0.0769 - val_accuracy: 0.9734\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0667 - accuracy: 0.9869 - val_loss: 0.0768 - val_accuracy: 0.9734\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0666 - accuracy: 0.9869 - val_loss: 0.0768 - val_accuracy: 0.9734\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 0.9869 - val_loss: 0.0767 - val_accuracy: 0.9734\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9869 - val_loss: 0.0767 - val_accuracy: 0.9734\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0663 - accuracy: 0.9869 - val_loss: 0.0766 - val_accuracy: 0.9734\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9869 - val_loss: 0.0765 - val_accuracy: 0.9734\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0661 - accuracy: 0.9869 - val_loss: 0.0763 - val_accuracy: 0.9734\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9869 - val_loss: 0.0764 - val_accuracy: 0.9734\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9869 - val_loss: 0.0763 - val_accuracy: 0.9734\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9869 - val_loss: 0.0762 - val_accuracy: 0.9734\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9895 - val_loss: 0.0760 - val_accuracy: 0.9734\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9895 - val_loss: 0.0760 - val_accuracy: 0.9734\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.9895 - val_loss: 0.0760 - val_accuracy: 0.9734\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0653 - accuracy: 0.9895 - val_loss: 0.0759 - val_accuracy: 0.9734\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9895 - val_loss: 0.0757 - val_accuracy: 0.9734\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9895 - val_loss: 0.0757 - val_accuracy: 0.9734\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0650 - accuracy: 0.9895 - val_loss: 0.0756 - val_accuracy: 0.9734\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9895 - val_loss: 0.0756 - val_accuracy: 0.9734\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9895 - val_loss: 0.0756 - val_accuracy: 0.9734\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9895 - val_loss: 0.0755 - val_accuracy: 0.9734\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9895 - val_loss: 0.0754 - val_accuracy: 0.9734\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9895 - val_loss: 0.0754 - val_accuracy: 0.9734\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9895 - val_loss: 0.0753 - val_accuracy: 0.9734\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0643 - accuracy: 0.9895 - val_loss: 0.0752 - val_accuracy: 0.9734\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0642 - accuracy: 0.9895 - val_loss: 0.0751 - val_accuracy: 0.9734\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0641 - accuracy: 0.9895 - val_loss: 0.0750 - val_accuracy: 0.9734\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9895 - val_loss: 0.0750 - val_accuracy: 0.9734\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9895 - val_loss: 0.0749 - val_accuracy: 0.9734\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9895 - val_loss: 0.0748 - val_accuracy: 0.9734\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0638 - accuracy: 0.9895 - val_loss: 0.0747 - val_accuracy: 0.9734\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 0.9895 - val_loss: 0.0746 - val_accuracy: 0.9734\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9895 - val_loss: 0.0746 - val_accuracy: 0.9734\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0635 - accuracy: 0.9895 - val_loss: 0.0744 - val_accuracy: 0.9734\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9895 - val_loss: 0.0744 - val_accuracy: 0.9734\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0633 - accuracy: 0.9895 - val_loss: 0.0743 - val_accuracy: 0.9734\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9895 - val_loss: 0.0743 - val_accuracy: 0.9734\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0631 - accuracy: 0.9895 - val_loss: 0.0742 - val_accuracy: 0.9734\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0630 - accuracy: 0.9895 - val_loss: 0.0742 - val_accuracy: 0.9734\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9895 - val_loss: 0.0741 - val_accuracy: 0.9734\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9895 - val_loss: 0.0741 - val_accuracy: 0.9734\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9895 - val_loss: 0.0739 - val_accuracy: 0.9734\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0627 - accuracy: 0.9895 - val_loss: 0.0739 - val_accuracy: 0.9734\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0626 - accuracy: 0.9895 - val_loss: 0.0739 - val_accuracy: 0.9734\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9895 - val_loss: 0.0738 - val_accuracy: 0.9734\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9895 - val_loss: 0.0736 - val_accuracy: 0.9734\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9895 - val_loss: 0.0736 - val_accuracy: 0.9734\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9895 - val_loss: 0.0736 - val_accuracy: 0.9734\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9895 - val_loss: 0.0735 - val_accuracy: 0.9734\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0621 - accuracy: 0.9895 - val_loss: 0.0735 - val_accuracy: 0.9734\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.9895 - val_loss: 0.0734 - val_accuracy: 0.9734\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9895 - val_loss: 0.0733 - val_accuracy: 0.9734\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0619 - accuracy: 0.9895 - val_loss: 0.0731 - val_accuracy: 0.9734\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.9895 - val_loss: 0.0731 - val_accuracy: 0.9734\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9895 - val_loss: 0.0732 - val_accuracy: 0.9734\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9895 - val_loss: 0.0731 - val_accuracy: 0.9734\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.9895 - val_loss: 0.0731 - val_accuracy: 0.9734\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9895 - val_loss: 0.0731 - val_accuracy: 0.9734\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9895 - val_loss: 0.0730 - val_accuracy: 0.9734\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9895 - val_loss: 0.0729 - val_accuracy: 0.9734\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 0.9895 - val_loss: 0.0728 - val_accuracy: 0.9734\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9895 - val_loss: 0.0727 - val_accuracy: 0.9734\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9895 - val_loss: 0.0727 - val_accuracy: 0.9734\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9895 - val_loss: 0.0727 - val_accuracy: 0.9734\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9895 - val_loss: 0.0726 - val_accuracy: 0.9734\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0608 - accuracy: 0.9895 - val_loss: 0.0726 - val_accuracy: 0.9734\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0607 - accuracy: 0.9895 - val_loss: 0.0724 - val_accuracy: 0.9734\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0606 - accuracy: 0.9895 - val_loss: 0.0724 - val_accuracy: 0.9734\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9895 - val_loss: 0.0724 - val_accuracy: 0.9734\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.9895 - val_loss: 0.0724 - val_accuracy: 0.9734\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9895 - val_loss: 0.0723 - val_accuracy: 0.9734\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9895 - val_loss: 0.0721 - val_accuracy: 0.9734\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9895 - val_loss: 0.0721 - val_accuracy: 0.9734\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9895 - val_loss: 0.0720 - val_accuracy: 0.9734\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9895 - val_loss: 0.0720 - val_accuracy: 0.9734\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9895 - val_loss: 0.0719 - val_accuracy: 0.9734\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0600 - accuracy: 0.9895 - val_loss: 0.0719 - val_accuracy: 0.9734\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9895 - val_loss: 0.0719 - val_accuracy: 0.9734\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9895 - val_loss: 0.0716 - val_accuracy: 0.9734\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9895 - val_loss: 0.0716 - val_accuracy: 0.9734\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0597 - accuracy: 0.9895 - val_loss: 0.0715 - val_accuracy: 0.9734\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9895 - val_loss: 0.0715 - val_accuracy: 0.9734\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9895 - val_loss: 0.0715 - val_accuracy: 0.9734\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0595 - accuracy: 0.9895 - val_loss: 0.0715 - val_accuracy: 0.9734\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9895 - val_loss: 0.0715 - val_accuracy: 0.9734\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9895 - val_loss: 0.0714 - val_accuracy: 0.9734\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0592 - accuracy: 0.9895 - val_loss: 0.0713 - val_accuracy: 0.9734\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9895 - val_loss: 0.0712 - val_accuracy: 0.9734\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9895 - val_loss: 0.0712 - val_accuracy: 0.9734\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9895 - val_loss: 0.0713 - val_accuracy: 0.9734\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0590 - accuracy: 0.9895 - val_loss: 0.0711 - val_accuracy: 0.9734\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9895 - val_loss: 0.0712 - val_accuracy: 0.9734\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0588 - accuracy: 0.9895 - val_loss: 0.0710 - val_accuracy: 0.9734\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9895 - val_loss: 0.0709 - val_accuracy: 0.9734\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9895 - val_loss: 0.0708 - val_accuracy: 0.9734\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9895 - val_loss: 0.0710 - val_accuracy: 0.9734\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 0.9895 - val_loss: 0.0709 - val_accuracy: 0.9734\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.9895 - val_loss: 0.0708 - val_accuracy: 0.9734\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.9895 - val_loss: 0.0708 - val_accuracy: 0.9734\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0584 - accuracy: 0.9895 - val_loss: 0.0707 - val_accuracy: 0.9734\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9895 - val_loss: 0.0707 - val_accuracy: 0.9734\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9895 - val_loss: 0.0705 - val_accuracy: 0.9787\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9895 - val_loss: 0.0705 - val_accuracy: 0.9787\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9895 - val_loss: 0.0705 - val_accuracy: 0.9787\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9895 - val_loss: 0.0702 - val_accuracy: 0.9787\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9895 - val_loss: 0.0702 - val_accuracy: 0.9787\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9895 - val_loss: 0.0702 - val_accuracy: 0.9787\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0579 - accuracy: 0.9895 - val_loss: 0.0702 - val_accuracy: 0.9787\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0578 - accuracy: 0.9895 - val_loss: 0.0702 - val_accuracy: 0.9787\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9895 - val_loss: 0.0701 - val_accuracy: 0.9787\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9895 - val_loss: 0.0703 - val_accuracy: 0.9787\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9895 - val_loss: 0.0702 - val_accuracy: 0.9787\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9895 - val_loss: 0.0701 - val_accuracy: 0.9787\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9895 - val_loss: 0.0700 - val_accuracy: 0.9787\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9895 - val_loss: 0.0700 - val_accuracy: 0.9787\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9895 - val_loss: 0.0699 - val_accuracy: 0.9787\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9895 - val_loss: 0.0699 - val_accuracy: 0.9787\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9895 - val_loss: 0.0699 - val_accuracy: 0.9787\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9895 - val_loss: 0.0697 - val_accuracy: 0.9787\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9895 - val_loss: 0.0697 - val_accuracy: 0.9787\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9895 - val_loss: 0.0696 - val_accuracy: 0.9787\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0570 - accuracy: 0.9895 - val_loss: 0.0696 - val_accuracy: 0.9787\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.9895 - val_loss: 0.0697 - val_accuracy: 0.9787\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9895 - val_loss: 0.0696 - val_accuracy: 0.9787\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0568 - accuracy: 0.9895 - val_loss: 0.0696 - val_accuracy: 0.9787\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9895 - val_loss: 0.0695 - val_accuracy: 0.9787\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9895 - val_loss: 0.0695 - val_accuracy: 0.9787\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9895 - val_loss: 0.0695 - val_accuracy: 0.9787\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0566 - accuracy: 0.9895 - val_loss: 0.0694 - val_accuracy: 0.9787\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9895 - val_loss: 0.0693 - val_accuracy: 0.9787\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9895 - val_loss: 0.0693 - val_accuracy: 0.9787\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9895 - val_loss: 0.0693 - val_accuracy: 0.9787\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9895 - val_loss: 0.0692 - val_accuracy: 0.9787\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9895 - val_loss: 0.0691 - val_accuracy: 0.9787\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0563 - accuracy: 0.9895 - val_loss: 0.0691 - val_accuracy: 0.9787\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9895 - val_loss: 0.0692 - val_accuracy: 0.9787\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9895 - val_loss: 0.0689 - val_accuracy: 0.9787\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9895 - val_loss: 0.0689 - val_accuracy: 0.9787\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9895 - val_loss: 0.0689 - val_accuracy: 0.9787\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0560 - accuracy: 0.9895 - val_loss: 0.0688 - val_accuracy: 0.9787\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9895 - val_loss: 0.0688 - val_accuracy: 0.9787\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9895 - val_loss: 0.0687 - val_accuracy: 0.9787\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9895 - val_loss: 0.0687 - val_accuracy: 0.9787\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9895 - val_loss: 0.0687 - val_accuracy: 0.9787\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0557 - accuracy: 0.9895 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0557 - accuracy: 0.9895 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9895 - val_loss: 0.0687 - val_accuracy: 0.9787\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0555 - accuracy: 0.9921 - val_loss: 0.0687 - val_accuracy: 0.9787\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9921 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9921 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9921 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0553 - accuracy: 0.9921 - val_loss: 0.0686 - val_accuracy: 0.9787\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9921 - val_loss: 0.0685 - val_accuracy: 0.9787\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9921 - val_loss: 0.0684 - val_accuracy: 0.9787\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9921 - val_loss: 0.0683 - val_accuracy: 0.9787\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9921 - val_loss: 0.0684 - val_accuracy: 0.9787\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9921 - val_loss: 0.0684 - val_accuracy: 0.9787\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9921 - val_loss: 0.0683 - val_accuracy: 0.9787\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9921 - val_loss: 0.0683 - val_accuracy: 0.9787\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9921 - val_loss: 0.0683 - val_accuracy: 0.9787\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9921 - val_loss: 0.0683 - val_accuracy: 0.9787\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0548 - accuracy: 0.9921 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9921 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9921 - val_loss: 0.0681 - val_accuracy: 0.9787\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9921 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9921 - val_loss: 0.0680 - val_accuracy: 0.9787\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9921 - val_loss: 0.0681 - val_accuracy: 0.9787\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9921 - val_loss: 0.0681 - val_accuracy: 0.9787\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0545 - accuracy: 0.9921 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9921 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9921 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9921 - val_loss: 0.0678 - val_accuracy: 0.9787\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0543 - accuracy: 0.9921 - val_loss: 0.0679 - val_accuracy: 0.9787\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9921 - val_loss: 0.0678 - val_accuracy: 0.9787\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9921 - val_loss: 0.0677 - val_accuracy: 0.9787\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9921 - val_loss: 0.0677 - val_accuracy: 0.9787\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9921 - val_loss: 0.0677 - val_accuracy: 0.9787\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9921 - val_loss: 0.0676 - val_accuracy: 0.9787\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0540 - accuracy: 0.9921 - val_loss: 0.0678 - val_accuracy: 0.9787\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9921 - val_loss: 0.0676 - val_accuracy: 0.9787\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9921 - val_loss: 0.0675 - val_accuracy: 0.9787\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9921 - val_loss: 0.0675 - val_accuracy: 0.9787\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9921 - val_loss: 0.0675 - val_accuracy: 0.9787\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0538 - accuracy: 0.9921 - val_loss: 0.0676 - val_accuracy: 0.9787\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9921 - val_loss: 0.0676 - val_accuracy: 0.9787\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9921 - val_loss: 0.0675 - val_accuracy: 0.9787\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.9921 - val_loss: 0.0675 - val_accuracy: 0.9787\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0536 - accuracy: 0.9921 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9921 - val_loss: 0.0673 - val_accuracy: 0.9787\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9921 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9921 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0534 - accuracy: 0.9921 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0534 - accuracy: 0.9921 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9921 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9921 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9921 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9921 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9921 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9921 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9921 - val_loss: 0.0672 - val_accuracy: 0.9787\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9921 - val_loss: 0.0670 - val_accuracy: 0.9787\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0530 - accuracy: 0.9921 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.9921 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9921 - val_loss: 0.0671 - val_accuracy: 0.9787\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9921 - val_loss: 0.0670 - val_accuracy: 0.9787\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9921 - val_loss: 0.0669 - val_accuracy: 0.9787\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9921 - val_loss: 0.0669 - val_accuracy: 0.9787\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0527 - accuracy: 0.9921 - val_loss: 0.0669 - val_accuracy: 0.9787\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9921 - val_loss: 0.0669 - val_accuracy: 0.9787\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9921 - val_loss: 0.0668 - val_accuracy: 0.9787\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9948 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.9948 - val_loss: 0.0668 - val_accuracy: 0.9787\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9948 - val_loss: 0.0666 - val_accuracy: 0.9787\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9948 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9948 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0524 - accuracy: 0.9948 - val_loss: 0.0668 - val_accuracy: 0.9787\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9948 - val_loss: 0.0666 - val_accuracy: 0.9787\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9948 - val_loss: 0.0666 - val_accuracy: 0.9787\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9948 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9948 - val_loss: 0.0667 - val_accuracy: 0.9787\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0522 - accuracy: 0.9948 - val_loss: 0.0666 - val_accuracy: 0.9787\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9948 - val_loss: 0.0665 - val_accuracy: 0.9787\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9948 - val_loss: 0.0665 - val_accuracy: 0.9787\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9948 - val_loss: 0.0665 - val_accuracy: 0.9787\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9948 - val_loss: 0.0665 - val_accuracy: 0.9787\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0514 - accuracy: 0.9948 - val_loss: 0.0664 - val_accuracy: 0.9787\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9948 - val_loss: 0.0663 - val_accuracy: 0.9787\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0511 - accuracy: 0.9948 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0511 - accuracy: 0.9948 - val_loss: 0.0659 - val_accuracy: 0.9787\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9948 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9948 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0509 - accuracy: 0.9948 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9948 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9948 - val_loss: 0.0660 - val_accuracy: 0.9787\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0508 - accuracy: 0.9948 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9787\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9948 - val_loss: 0.0661 - val_accuracy: 0.9787\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9948 - val_loss: 0.0660 - val_accuracy: 0.9787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model for loss and accuracy\n",
        "\n",
        "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
        "print(\"Test score:\", model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "id": "kONCF5o7kekT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99ba6c1-6fee-4396-84f9-79f4daf2fd71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9948\n",
            "Train score: [0.05058881640434265, 0.9947506785392761]\n",
            "6/6 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9787\n",
            "Test score: [0.06603600084781647, 0.978723406791687]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot loss per iteration\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(r.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "qFKJi4vmlFl4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a0484b9c-048b-4b09-db57-d61ca432d99b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3b6d173490>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot accuracy per iteration\n",
        "plt.plot(r.history[\"accuracy\"], label=\"acc\")\n",
        "plt.plot(r.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "rUlcdOOQmLFy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "afeaf9b4-cd78-47f2-ab5f-a1e881b8d16d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3b6c157b90>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions"
      ],
      "metadata": {
        "id": "o_FA1UZlaQ-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "P = model.predict(X_test)\n",
        "P # outputs of the sigmoid, interpreted as \"probability that y is equal to 1 given x\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCk5w5kYaUrz",
        "outputId": "4e3e0e8e-36e1-42e3-d09a-9a7035a1bbab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.40952998e-01],\n",
              "       [6.40628859e-05],\n",
              "       [9.99984562e-01],\n",
              "       [9.67904091e-01],\n",
              "       [5.17929196e-02],\n",
              "       [4.03094398e-12],\n",
              "       [9.99676168e-01],\n",
              "       [9.97016728e-01],\n",
              "       [2.79137492e-03],\n",
              "       [9.99836922e-01],\n",
              "       [3.93262237e-01],\n",
              "       [1.30218245e-08],\n",
              "       [9.99811411e-01],\n",
              "       [1.00000000e+00],\n",
              "       [2.62171030e-03],\n",
              "       [9.98954058e-01],\n",
              "       [9.99971569e-01],\n",
              "       [9.90458965e-01],\n",
              "       [1.88109539e-07],\n",
              "       [9.96797383e-01],\n",
              "       [9.99458313e-01],\n",
              "       [9.99680817e-01],\n",
              "       [3.85344028e-04],\n",
              "       [9.99570251e-01],\n",
              "       [8.51723015e-01],\n",
              "       [4.55074310e-02],\n",
              "       [9.78054166e-01],\n",
              "       [9.99984503e-01],\n",
              "       [9.99989450e-01],\n",
              "       [9.98578429e-01],\n",
              "       [9.99996126e-01],\n",
              "       [9.92093444e-01],\n",
              "       [9.99994934e-01],\n",
              "       [9.99283075e-01],\n",
              "       [9.99028862e-01],\n",
              "       [9.99998569e-01],\n",
              "       [9.93435979e-01],\n",
              "       [3.12897563e-02],\n",
              "       [1.59919878e-07],\n",
              "       [9.99719083e-01],\n",
              "       [1.53973639e-01],\n",
              "       [9.94519770e-01],\n",
              "       [1.00000000e+00],\n",
              "       [7.17775226e-01],\n",
              "       [2.94439299e-11],\n",
              "       [9.99985635e-01],\n",
              "       [9.97375488e-01],\n",
              "       [9.99701738e-01],\n",
              "       [9.99806464e-01],\n",
              "       [6.77633409e-07],\n",
              "       [9.90639091e-01],\n",
              "       [9.62474227e-01],\n",
              "       [9.99625504e-01],\n",
              "       [3.45706940e-04],\n",
              "       [9.99907434e-01],\n",
              "       [9.95295644e-01],\n",
              "       [7.76513431e-09],\n",
              "       [9.99734402e-01],\n",
              "       [8.31004977e-01],\n",
              "       [9.98525739e-01],\n",
              "       [9.97324944e-01],\n",
              "       [9.99345660e-01],\n",
              "       [9.99976099e-01],\n",
              "       [9.93281364e-01],\n",
              "       [9.99995708e-01],\n",
              "       [9.99908447e-01],\n",
              "       [9.99999046e-01],\n",
              "       [7.51895249e-01],\n",
              "       [9.99997258e-01],\n",
              "       [9.99936700e-01],\n",
              "       [9.50389981e-01],\n",
              "       [9.99875784e-01],\n",
              "       [3.58374715e-02],\n",
              "       [9.99609232e-01],\n",
              "       [9.99995112e-01],\n",
              "       [9.92078185e-01],\n",
              "       [2.67774199e-15],\n",
              "       [9.99971390e-01],\n",
              "       [9.99913812e-01],\n",
              "       [9.68141079e-01],\n",
              "       [2.27135675e-15],\n",
              "       [9.99996305e-01],\n",
              "       [9.99447703e-01],\n",
              "       [9.22471058e-11],\n",
              "       [9.99980271e-01],\n",
              "       [9.99091625e-01],\n",
              "       [1.55335272e-07],\n",
              "       [1.37062291e-12],\n",
              "       [9.99998808e-01],\n",
              "       [9.29767787e-01],\n",
              "       [9.90498662e-01],\n",
              "       [9.98435020e-01],\n",
              "       [9.98094559e-01],\n",
              "       [1.08826671e-13],\n",
              "       [9.60876465e-01],\n",
              "       [1.85614190e-05],\n",
              "       [9.99996364e-01],\n",
              "       [9.99981999e-01],\n",
              "       [1.48499012e-03],\n",
              "       [9.99929786e-01],\n",
              "       [5.21064345e-15],\n",
              "       [6.56997263e-02],\n",
              "       [2.05159187e-04],\n",
              "       [3.46039999e-27],\n",
              "       [2.32060684e-05],\n",
              "       [5.89836759e-07],\n",
              "       [9.99973059e-01],\n",
              "       [1.35230351e-11],\n",
              "       [5.62772002e-05],\n",
              "       [9.99166131e-01],\n",
              "       [8.17835330e-21],\n",
              "       [9.97207940e-01],\n",
              "       [9.99508321e-01],\n",
              "       [9.99694526e-01],\n",
              "       [9.99976695e-01],\n",
              "       [7.52647438e-08],\n",
              "       [9.98499155e-01],\n",
              "       [5.24965167e-01],\n",
              "       [9.99930143e-01],\n",
              "       [3.60444188e-03],\n",
              "       [8.51301751e-10],\n",
              "       [8.27308834e-01],\n",
              "       [9.99784827e-01],\n",
              "       [4.58717346e-04],\n",
              "       [8.91593521e-10],\n",
              "       [1.00000000e+00],\n",
              "       [9.68538225e-01],\n",
              "       [9.99299407e-01],\n",
              "       [1.50273442e-01],\n",
              "       [9.99964297e-01],\n",
              "       [3.14399955e-07],\n",
              "       [9.26335216e-01],\n",
              "       [9.97849166e-01],\n",
              "       [1.07443902e-05],\n",
              "       [3.11839581e-03],\n",
              "       [8.50930917e-08],\n",
              "       [5.64485788e-03],\n",
              "       [1.32539272e-02],\n",
              "       [9.99995232e-01],\n",
              "       [9.99994516e-01],\n",
              "       [9.97745872e-01],\n",
              "       [1.23407272e-05],\n",
              "       [9.99989510e-01],\n",
              "       [6.16448224e-02],\n",
              "       [5.87571139e-06],\n",
              "       [9.99316573e-01],\n",
              "       [9.99737859e-01],\n",
              "       [7.55393955e-07],\n",
              "       [2.21696496e-02],\n",
              "       [9.99953806e-01],\n",
              "       [8.54483843e-01],\n",
              "       [5.98222017e-04],\n",
              "       [1.84271976e-05],\n",
              "       [9.99721408e-01],\n",
              "       [9.96970773e-01],\n",
              "       [9.34958337e-07],\n",
              "       [2.51469016e-03],\n",
              "       [3.11682485e-10],\n",
              "       [9.78775144e-01],\n",
              "       [2.05945321e-06],\n",
              "       [9.99993086e-01],\n",
              "       [8.59408556e-06],\n",
              "       [1.41471624e-04],\n",
              "       [1.38202310e-03],\n",
              "       [9.99999404e-01],\n",
              "       [8.80511038e-07],\n",
              "       [1.46725451e-10],\n",
              "       [8.90851021e-04],\n",
              "       [9.98817921e-01],\n",
              "       [9.99962270e-01],\n",
              "       [1.15933001e-01],\n",
              "       [9.88504767e-01],\n",
              "       [9.99974370e-01],\n",
              "       [8.38598524e-08],\n",
              "       [5.34953060e-09],\n",
              "       [9.99774814e-01],\n",
              "       [9.77691352e-01],\n",
              "       [9.99871850e-01],\n",
              "       [1.71139836e-03],\n",
              "       [9.99583483e-01],\n",
              "       [9.99998927e-01],\n",
              "       [9.98943031e-01],\n",
              "       [9.49475884e-01],\n",
              "       [9.99999166e-01],\n",
              "       [4.86957923e-08],\n",
              "       [9.98741567e-01],\n",
              "       [3.93342078e-02],\n",
              "       [9.99993801e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# round to get the actual predictions \n",
        "# must flatten since targets and predictions are not same shape\n",
        "import numpy as np\n",
        "P = np.round(P).flatten()\n",
        "P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9VKViAGaaIM",
        "outputId": "4532ee11-1f7f-4934-ab50-5746ed451e6f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
              "       1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
              "       1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate accuracy\n",
        "print(\"Manually calculated accuracy:\", np.mean(P==y_test))\n",
        "print(\"Evaluate output:\", model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlymY_yDbPF3",
        "outputId": "2bb5c9af-b48f-4adb-8f0a-46f69841a915"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually calculated accuracy: 0.9787234042553191\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9787\n",
            "Evaluate output: [0.06603600084781647, 0.978723406791687]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G6mZu3W2bto7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}